{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a href=\"https://www.cognitiveclass.ai\"><img src = \"https://cognitiveclass.ai/wp-content/themes/bdu3.0/static/images/cc-logo.png\" align = left></a>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "--------------------\n",
    "# SETI CNN using TF and Binary DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /usr/local/lib/python2.7/dist-packages\r\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python2.7/dist-packages (from sklearn)\r\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "#import ibmseti\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import time\n",
    "!sudo pip install sklearn\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from six.moves import urllib\n",
    "import sys\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set your team folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/SETI1_data\n",
      "/tmp/SETI1_train\n"
     ]
    }
   ],
   "source": [
    "### SET YOUR TEAM NAME HERE! Use this folder to save intermediate results\n",
    "mydatafolder = \"/tmp/SETI1_data\"\n",
    "if os.path.exists(mydatafolder) is False:\n",
    "    os.makedirs(mydatafolder)\n",
    "print mydatafolder\n",
    "\n",
    "train_dir = '/tmp/SETI1_train'\n",
    "if os.path.exists(train_dir) is False:\n",
    "    os.makedirs(train_dir)\n",
    "print train_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Import dataset reader\n",
    "The following cell will load a python code to read the SETI dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  SETI.zip\r\n",
      "  inflating: SETI.py                 \r\n",
      "  inflating: __MACOSX/._SETI.py      \r\n"
     ]
    }
   ],
   "source": [
    "!wget -q --output-document  SETI.zip  https://ibm.box.com/shared/static/jhqdhcblhua5dx2t7ixwm88okitjrl6l.zip\n",
    "!unzip -o SETI.zip\n",
    "import SETI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "('Successfully downloaded', 'qz33lcio9ip2j8qi2atxqs62gn3bnu2s.gz', 2432541, 'bytes.')\n"
     ]
    }
   ],
   "source": [
    "def maybe_download_and_extract():\n",
    "    data_dir = \"/tmp/SETI1_data\"\n",
    "    DATA_URL =  'https://ibm.box.com/shared/static/qz33lcio9ip2j8qi2atxqs62gn3bnu2s.gz'\n",
    "    dest_directory = data_dir\n",
    "    if not os.path.exists(dest_directory):\n",
    "        os.makedirs(dest_directory)\n",
    "    filename = DATA_URL.split('/')[-1]\n",
    "    filepath = os.path.join(dest_directory, filename)\n",
    "    if not os.path.exists(filepath):\n",
    "        def _progress(count, block_size, total_size):\n",
    "            sys.stdout.write('\\r>> Downloading %s %.1f%%' % (filename, float(count * block_size) / float(total_size) * 100.0))\n",
    "        sys.stdout.flush()\n",
    "        filepath, _ = urllib.request.urlretrieve(DATA_URL, filepath, _progress)\n",
    "    print()\n",
    "    statinfo = os.stat(filepath)\n",
    "    print('Successfully downloaded', filename, statinfo.st_size, 'bytes.')\n",
    "    extracted_dir_path = os.path.join(dest_directory, 'SETI_ds_64x128')\n",
    "    if not os.path.exists(extracted_dir_path):\n",
    "        tarfile.open(filepath, 'r:gz').extractall(dest_directory)\n",
    "maybe_download_and_extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Load data SETI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/SETI1_data/SETI_ds_64x128/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/SETI1_data/SETI_ds_64x128/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/SETI1_data/SETI_ds_64x128/test-images-idx3-ubyte.gz\n",
      "Extracting /tmp/SETI1_data/SETI_ds_64x128/test-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(694, 8192)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_directory = mydatafolder + '/SETI_ds_64x128/'\n",
    "dataset = SETI.read_data_sets(ds_directory, one_hot=True, validation_size=0)\n",
    "dataset.train.images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Network Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "decay_rate=0.96  #decay every 1000 steps with a base of 0.96:\n",
    "decay_steps=1000\n",
    "learning_rate = 0.005\n",
    "training_epochs = 300\n",
    "batch_size = 50\n",
    "display_step = 100\n",
    "MOVING_AVERAGE_DECAY = 0.9999     # The decay to use for the moving average.\n",
    "use_fp16 = False\n",
    "\n",
    "#check point directory\n",
    "chk_directory = train_dir+'/save/'\n",
    "checkpoint_path = chk_directory + 'model.ckpt'\n",
    "\n",
    "\n",
    "NUM_CLASSES = 4 # number of possible classifications for the problem\n",
    "dropout = 0.50 # Dropout, probability to keep units\n",
    "\n",
    "height = 64 # height of the image in pixels \n",
    "width = 128 # width of the image in pixels \n",
    "n_input = width * height # number of pixels in one image \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _variable_with_weight_decay(name, shape, stddev, wd):\n",
    "    #wd: add L2Loss weight decay multiplied by this float. If None, weight decay is not added for this Variable.\n",
    "    dtype = tf.float16 if use_fp16 else tf.float32\n",
    "    var = _variable_on_cpu(name, shape,tf.truncated_normal_initializer(stddev=stddev, dtype=dtype))\n",
    "    if wd is not None:\n",
    "        weight_decay = tf.multiply(tf.nn.l2_loss(var), wd, name='weight_loss')\n",
    "        tf.add_to_collection('losses', weight_decay)\n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _variable_on_cpu(name, shape, initializer):\n",
    "    with tf.device('/cpu:0'):\n",
    "        dtype = tf.float16 if use_fp16 else tf.float32\n",
    "        var = tf.get_variable(name, shape, initializer=initializer, dtype=dtype)\n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference(images):\n",
    "    # We instantiate all variables using tf.get_variable() instead of\n",
    "    # tf.Variable() in order to share variables across multiple GPU training runs.\n",
    "    # If we only ran this model on a single GPU, we could simplify this function\n",
    "    # by replacing all instances of tf.get_variable() with tf.Variable().\n",
    "    #\n",
    "    # conv1\n",
    "    with tf.variable_scope('conv1') as scope:\n",
    "        kernel = _variable_with_weight_decay('weights', shape=[5, 5, 1, 32], stddev=0.1,  wd=0.0)\n",
    "        conv = tf.nn.conv2d(images, kernel, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        biases = _variable_on_cpu('biases', [32], tf.constant_initializer(0.1))\n",
    "        pre_activation = tf.nn.bias_add(conv, biases)\n",
    "        conv1 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "        #_activation_summary(conv1)\n",
    "\n",
    "    # pool1\n",
    "    pool1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name='pool1')\n",
    "    # norm1\n",
    "    norm1 = tf.nn.lrn(pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm1')\n",
    "\n",
    "    # conv2\n",
    "    with tf.variable_scope('conv2') as scope:\n",
    "        kernel = _variable_with_weight_decay('weights', shape=[5, 5, 32, 64],  stddev=0.1,  wd=0.0)\n",
    "        conv = tf.nn.conv2d(norm1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "        biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.1))\n",
    "        pre_activation = tf.nn.bias_add(conv, biases)\n",
    "        conv2 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "        #_activation_summary(conv2)\n",
    "\n",
    "    # norm2\n",
    "    norm2 = tf.nn.lrn(conv2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,  name='norm2')\n",
    "    # pool2\n",
    "    pool2 = tf.nn.max_pool(norm2, ksize=[1, 2, 2, 1], strides=[1, 4, 4, 1], padding='SAME', name='pool2')\n",
    "    \n",
    "    \n",
    "    # local3\n",
    "    with tf.variable_scope('local3') as scope:\n",
    "        # Move everything into depth so we can perform a single matrix multiply.\n",
    "        reshape = tf.reshape(pool2, [batch_size, -1])\n",
    "        dim = reshape.get_shape()[1].value\n",
    "        weights = _variable_with_weight_decay('weights', shape=[dim, 1024], stddev=0.04, wd=0.004)\n",
    "        biases = _variable_on_cpu('biases', [1024], tf.constant_initializer(0.1))\n",
    "        local3 = tf.nn.relu(tf.matmul(reshape, weights) + biases, name=scope.name)\n",
    "        #_activation_summary(local3)\n",
    "\n",
    "    # local4\n",
    "    with tf.variable_scope('local4') as scope:\n",
    "        weights = _variable_with_weight_decay('weights', shape=[1024, 256],  stddev=0.04, wd=0.004)\n",
    "        biases = _variable_on_cpu('biases', [256], tf.constant_initializer(0.1))\n",
    "        local4 = tf.nn.relu(tf.matmul(local3, weights) + biases, name=scope.name)\n",
    "        #_activation_summary(local4)\n",
    "\n",
    "    # linear layer(WX + b),\n",
    "    # We don't apply softmax here because\n",
    "    # tf.nn.sparse_softmax_cross_entropy_with_logits accepts the unscaled logits\n",
    "    # and performs the softmax internally for efficiency.\n",
    "    with tf.variable_scope('softmax_linear') as scope:\n",
    "        weights = _variable_with_weight_decay('weights', [256, NUM_CLASSES],  stddev=1/256.0, wd=0.0)\n",
    "        biases = _variable_on_cpu('biases', [NUM_CLASSES], tf.constant_initializer(0.0))\n",
    "        softmax_linear = tf.add(tf.matmul(local4, weights), biases, name=scope.name)\n",
    "    #_activation_summary(softmax_linear)\n",
    "\n",
    "    return softmax_linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_loss(logits, labels):\n",
    "    \"\"\"Add L2Loss to all the trainable variables.\"\"\"\n",
    "    # Calculate the average cross entropy loss across the batch.\n",
    "    labels = tf.cast(labels, tf.int64)\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=logits, name='cross_entropy_per_example')\n",
    "    cross_entropy_mean = tf.reduce_mean(cross_entropy, name='cross_entropy')\n",
    "    tf.add_to_collection('losses', cross_entropy_mean)\n",
    "\n",
    "    # The total loss is defined as the cross entropy loss plus all of the weight decay terms (L2 loss).\n",
    "    return tf.add_n(tf.get_collection('losses'), name='total_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the total loss on a single tower running the SETI model.\n",
    "def tower_loss(scope, images, labels):\n",
    "    # Build inference Graph.\n",
    "    logits = inference(images)\n",
    "    _=calc_loss(logits, labels)\n",
    "\n",
    "    # Assemble all of the losses for the current tower only.\n",
    "    # 'losses' is the key for collection\n",
    "    # scope is for e.g. 'tower_0'\n",
    "    losses = tf.get_collection('losses', scope)\n",
    "\n",
    "    # Calculate the total loss for the current tower.\n",
    "    total_loss = tf.add_n(losses, name='total_loss')\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradients\n",
    "  \"\"\"Calculate the average gradient for each shared variable across all towers.\n",
    "\n",
    "  Note that this function provides a synchronization point across all towers.\n",
    "\n",
    "  Args:\n",
    "    tower_grads: List of lists of (gradient, variable) tuples. The outer list\n",
    "      is over individual gradients. The inner list is over the gradient\n",
    "      calculation for each tower.\n",
    "  Returns:\n",
    "     List of pairs of (gradient, variable) where the gradient has been averaged\n",
    "     across all towers.\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def average_gradients(tower_grads):\n",
    "    average_grads = []\n",
    "    for grad_and_vars in zip(*tower_grads):\n",
    "    # Note that each grad_and_vars looks like the following:\n",
    "    #   ((grad0_gpu0, var0_gpu0), ... , (grad0_gpuN, var0_gpuN))\n",
    "        grads = []\n",
    "        for g, _ in grad_and_vars:\n",
    "            # Add 0 dimension to the gradients to represent the tower.\n",
    "            expanded_g = tf.expand_dims(g, 0)\n",
    "\n",
    "            # Append on a 'tower' dimension which we will average over below.\n",
    "            grads.append(expanded_g)\n",
    "\n",
    "        # Average over the 'tower' dimension.\n",
    "        grad = tf.concat(axis=0, values=grads)\n",
    "        grad = tf.reduce_mean(grad, 0)\n",
    "\n",
    "        # Keep in mind that the Variables are redundant because they are shared\n",
    "        # across towers. So .. we will just return the first tower's pointer to\n",
    "        # the Variable.\n",
    "        v = grad_and_vars[0][1]\n",
    "        grad_and_var = (grad, v)\n",
    "        average_grads.append(grad_and_var)\n",
    "    return average_grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Create a variable to track the global step.\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "\n",
    "# create learning_decay\n",
    "# Decay the learning rate exponentially based on the number of steps.\n",
    "lr = tf.train.exponential_decay( learning_rate,\n",
    "                                 global_step,\n",
    "                                 decay_steps,\n",
    "                                 decay_rate, staircase=True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Use the optimizer to apply the gradients that minimize the loss\n",
    "# (and also increment the global step counter) as a single training step.\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr)\n",
    "\n",
    "# Calculate the gradients for the batch of data on this SETI tower.\n",
    "#grads = opt.compute_gradients(loss)\n",
    "\n",
    "#train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "#train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get images and labels for SETI.\n",
    "x_batch, y_batch = dataset.train.next_batch(batch_size,shuffle=True)\n",
    "x_image = tf.reshape(x_batch, [-1,height,width,1]) \n",
    "labels = tf.reshape(y_batch,[-1,NUM_CLASSES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with tf.Session() as sess:\n",
    "#     with tf.name_scope(\"test12\"):\n",
    "#         logit1 = inference(x_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the gradients for each model tower.\n",
    "tower_grads = []\n",
    "with tf.variable_scope(tf.get_variable_scope()):\n",
    "    for i in xrange(4):\n",
    "        with tf.device('/gpu:%d' % i):\n",
    "            with tf.name_scope('%s_%d' % ('tower_', i)) as scope:\n",
    "            # Dequeues one batch for the GPU\n",
    "            #image_batch, label_batch = batch_queue.dequeue()\n",
    "                x_batch, y_batch = dataset.train.next_batch(batch_size,shuffle=True)\n",
    "                image_batch = tf.reshape(x_batch, [-1,height,width,1]) \n",
    "                #label_batch = tf.reshape(y_batch,[-1,NUM_CLASSES])\n",
    "                # Calculate the loss for one tower of the SETI model. This function\n",
    "                # constructs the entire SETI model but shares the variables across\n",
    "                # all towers.\n",
    "                loss = tower_loss(scope, image_batch, y_batch)\n",
    "                # Reuse variables for the next tower.\n",
    "                tf.get_variable_scope().reuse_variables()\n",
    "                grads = optimizer.compute_gradients(loss)\n",
    "                tower_grads.append(grads)\n",
    "# on CPU                \n",
    "grads = average_gradients(tower_grads)\n",
    "# Apply the gradients to adjust the shared variables.\n",
    "apply_gradient_op = optimizer.apply_gradients(grads, global_step=global_step)\n",
    "\n",
    "# Track the moving averages of all trainable variables.\n",
    "variable_averages = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY, global_step)\n",
    "variables_averages_op = variable_averages.apply(tf.trainable_variables())\n",
    "\n",
    "# Group all updates to into a single train op.\n",
    "# we call train_op in learning process\n",
    "# tf.group Creates an op that groups multiple operations.\n",
    "# When this op finishes, all ops in input have finished. This op has no output.\n",
    "train_op = tf.group(apply_gradient_op, variables_averages_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def evaluate():\n",
    "    X_test = dataset.test.images\n",
    "    image_test = tf.reshape(X_test, [-1,height,width,1]) \n",
    "    y_test = dataset.test.labels\n",
    "    # Build a Graph that computes the logits predictions from the\n",
    "    # inference model.\n",
    "    with tf.name_scope('xx') as scope:\n",
    "        logits_test = inference(image_test)\n",
    "        # Calculate predictions.\n",
    "    top_k_op = tf.nn.in_top_k(logits_test, y_test, 1)\n",
    "    return top_k_op\n",
    "with tf.name_scope(\"t\"):\n",
    "    evaluate()\n",
    "    \n",
    "correct_prediction = tf.equal(tf.argmax(logits,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Create checkpoint directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_checkpoint_path: \"/tmp/SETI1_train/save/model.ckpt-3600\"\n",
      "all_model_checkpoint_paths: \"/tmp/SETI1_train/save/model.ckpt-3600\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "directory = os.path.dirname(chk_directory)\n",
    "try:\n",
    "    os.stat(directory)\n",
    "    ckpt = tf.train.get_checkpoint_state(chk_directory)\n",
    "    print ckpt\n",
    "except:\n",
    "    os.mkdir(directory) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model:  /tmp/SETI1_train/save/model.ckpt-3600\n"
     ]
    }
   ],
   "source": [
    "loss_values = []\n",
    "\n",
    "X_test = dataset.test.images\n",
    "y_test = dataset.test.labels\n",
    "\n",
    "sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n",
    "sess.run(init)\n",
    "saver = tf.train.Saver(tf.global_variables())\n",
    "\n",
    "# load previously trained model if appilcable\n",
    "ckpt = tf.train.get_checkpoint_state(chk_directory)\n",
    "if ckpt:\n",
    "    print \"loading model: \",ckpt.model_checkpoint_path\n",
    "    #saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "694"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step = 0\n",
    "num_examples = dataset.train.num_examples\n",
    "num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 , g_step: 0013 , E_time= 3.12278 , lr= 0.005000000 , cost= 22.791343689\n",
      "Epoch: 0011 , g_step: 0143 , E_time= 1.16217 , lr= 0.005000000 , cost= 22.511104584\n",
      "Epoch: 0021 , g_step: 0273 , E_time= 0.94890 , lr= 0.005000000 , cost= 22.074296951\n",
      "Epoch: 0031 , g_step: 0403 , E_time= 1.02329 , lr= 0.005000000 , cost= 21.925960541\n",
      "Epoch: 0041 , g_step: 0533 , E_time= 1.02493 , lr= 0.005000000 , cost= 21.807170868\n",
      "Epoch: 0051 , g_step: 0663 , E_time= 0.98137 , lr= 0.005000000 , cost= 21.692955017\n",
      "Epoch: 0061 , g_step: 0793 , E_time= 0.96134 , lr= 0.005000000 , cost= 21.580648422\n",
      "Epoch: 0071 , g_step: 0923 , E_time= 0.94387 , lr= 0.005000000 , cost= 21.469640732\n",
      "Epoch: 0081 , g_step: 1053 , E_time= 0.98540 , lr= 0.004800000 , cost= 21.361644745\n",
      "Epoch: 0091 , g_step: 1183 , E_time= 1.03355 , lr= 0.004800000 , cost= 21.257289886\n",
      "Epoch: 0101 , g_step: 1313 , E_time= 0.97650 , lr= 0.004800000 , cost= 21.153923035\n",
      "Epoch: 0111 , g_step: 1443 , E_time= 0.97179 , lr= 0.004800000 , cost= 21.051519394\n",
      "Epoch: 0121 , g_step: 1573 , E_time= 1.05745 , lr= 0.004800000 , cost= 20.949987411\n",
      "Epoch: 0131 , g_step: 1703 , E_time= 1.00197 , lr= 0.004800000 , cost= 20.849210739\n",
      "Epoch: 0141 , g_step: 1833 , E_time= 0.99739 , lr= 0.004800000 , cost= 20.749164581\n",
      "Epoch: 0151 , g_step: 1963 , E_time= 0.89525 , lr= 0.004800000 , cost= 20.649671555\n",
      "Epoch: 0161 , g_step: 2093 , E_time= 1.00120 , lr= 0.004608000 , cost= 20.553483963\n",
      "Epoch: 0171 , g_step: 2223 , E_time= 1.05579 , lr= 0.004608000 , cost= 20.459869385\n",
      "Epoch: 0181 , g_step: 2353 , E_time= 0.96705 , lr= 0.004608000 , cost= 20.370906830\n",
      "Epoch: 0191 , g_step: 2483 , E_time= 1.04854 , lr= 0.004608000 , cost= 20.275054932\n",
      "Epoch: 0201 , g_step: 2613 , E_time= 0.99031 , lr= 0.004608000 , cost= 20.180910110\n",
      "Epoch: 0211 , g_step: 2743 , E_time= 1.00257 , lr= 0.004608000 , cost= 20.085830688\n",
      "Epoch: 0221 , g_step: 2873 , E_time= 1.03195 , lr= 0.004608000 , cost= 19.992551804\n",
      "Epoch: 0231 , g_step: 3003 , E_time= 1.01149 , lr= 0.004423679 , cost= 19.900182724\n",
      "Epoch: 0241 , g_step: 3133 , E_time= 1.06340 , lr= 0.004423679 , cost= 19.812759399\n",
      "Epoch: 0251 , g_step: 3263 , E_time= 0.92833 , lr= 0.004423679 , cost= 19.726091385\n",
      "Epoch: 0261 , g_step: 3393 , E_time= 0.95666 , lr= 0.004423679 , cost= 19.638267517\n",
      "Epoch: 0271 , g_step: 3523 , E_time= 1.04591 , lr= 0.004423679 , cost= 19.550878525\n",
      "Epoch: 0281 , g_step: 3653 , E_time= 0.98305 , lr= 0.004423679 , cost= 19.464778900\n",
      "Epoch: 0291 , g_step: 3783 , E_time= 1.02958 , lr= 0.004423679 , cost= 19.383249283\n",
      "Optimization Finished!\n",
      "model saved to /tmp/SETI1_train/save/model.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/tmp/SETI1_train/save/model.ckpt-3600'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training cycle\n",
    "for epoch in range(training_epochs):\n",
    "    avg_loss = 0.\n",
    "    avg_accuracy = 0.\n",
    "    #dataset.shuffle_data()\n",
    "    total_batch = int(num_examples / batch_size)\n",
    "\n",
    "    # Loop over all batches in one epoch\n",
    "    start = time.time()\n",
    "    for step in range(total_batch):\n",
    "        _, loss_value = sess.run([train_op, loss])\n",
    "        assert not np.isnan(loss_value), 'Model diverged with loss = NaN'\n",
    "    end = time.time()    \n",
    "    # Display model every 1 epochs\n",
    "    if epoch >= 0 and epoch % 10 == 0:\n",
    "        plr = sess.run(lr)\n",
    "        g_step = sess.run(global_step)\n",
    "        loss_values.append(loss_value)\n",
    "        print \"Epoch:\", '%04d' % (epoch+1) , \", g_step:\", '%04d' % (g_step) , \", E_time=\" , \"{:.5f}\".format(end - start) , \", lr=\", \"{:.9f}\".format(plr), \", cost=\", \"{:.9f}\".format(loss_value)\n",
    "print(\"Optimization Finished!\")\n",
    "print (\"model saved to {}\".format(checkpoint_path))\n",
    "saver.save(sess, checkpoint_path, global_step = (epoch+1)*step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEACAYAAABfxaZOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x3fff7e98a2d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot([np.mean(loss_values[i:i+5]) for i in range(len(loss_values))])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Authors\n",
    "\n",
    "<div class=\"teacher-image\" style=\"    float: left;\n",
    "    width: 115px;\n",
    "    height: 115px;\n",
    "    margin-right: 10px;\n",
    "    margin-bottom: 10px;\n",
    "    border: 1px solid #CCC;\n",
    "    padding: 3px;\n",
    "    border-radius: 3px;\n",
    "    text-align: center;\"><img class=\"alignnone wp-image-2258 \" src=\"https://ibm.box.com/shared/static/tyd41rlrnmfrrk78jx521eb73fljwvv0.jpg\" alt=\"Saeed Aghabozorgi\" width=\"178\" height=\"178\" /></div>\n",
    "#### Saeed Aghabozorgi\n",
    "\n",
    "[Saeed Aghabozorgi](https://ca.linkedin.com/in/saeedaghabozorgi), PhD is Sr. Data Scientist in IBM with a track record of developing enterprise level applications that substantially increases clientsâ€™ ability to turn data into actionable knowledge. He is a researcher in data mining field and expert in developing advanced analytic methods like machine learning and statistical modelling on large datasets.</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
